{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy GCN Model Ample Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/aw1223/ip/agile/\")\n",
    "\n",
    "from sdk.ample import Ample\n",
    "\n",
    "from sdk.graphs.random_graph import RandomGraph\n",
    "\n",
    "#TODO change to just models in file sturcture\n",
    "from sdk.models.models import GCN_Model, GAT_Model, GraphSAGE_Model, GIN_Model, GCN_MLP_Model, MLP_Model, Edge_Embedding_Model, Interaction_Net_Model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ample = Ample()\n",
    "edge = True\n",
    "\n",
    "#TODO fix this : If model does not use edges, dont set edges to be true - will brrak things \n",
    "graph = RandomGraph(num_nodes=10, avg_degree=1, num_channels=32, graph_precision=\"FLOAT_32\",edge_dim=32,edges = edge) #TODO add var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trace model, find the constituent models e.g GCN, Interaction net and create a data flow graph\n",
    "\n",
    "model_cls = MLP_Model\n",
    "\n",
    "model = model_cls()\n",
    "\n",
    "\n",
    "# tracer = GraphTracer(model)\n",
    "# tracer.get_input_output_layers()\n",
    "# # tracer.print_input_output_layers()\n",
    "# tracer.draw()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 12318.07it/s]\n"
     ]
    }
   ],
   "source": [
    "#Use initalize to construct memory map for each model and then string together the dataflow between models\n",
    "#For each mode, init mem and store to seperate files?\n",
    "ample.initialize_memory(model,graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ample.sim()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Program Agile using device\n",
    "# ample.copy_data_to_device(data_file_name)\n",
    "# ample.execute()\n",
    "# ample.retrieve_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural-LAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(dataset='meps_example', model='graph_lam', subset_ds=0, seed=42, n_workers=4, epochs=200, batch_size=1, load=None, restore_opt=0, precision=32, graph='1level', hidden_dim=32, hidden_layers=1, processor_layers=1, mesh_aggr='sum', output_std=0, ar_steps=1, control_only=0, loss='wmse', step_length=3, lr=0.001, val_interval=1, eval='test', n_example_pred=1)\n",
      "args meps_example\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import random\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "# Third-party\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from lightning_fabric.utilities import seed\n",
    "\n",
    "# First-party\n",
    "from neural_lam import constants, utils\n",
    "from neural_lam.models.graph_lam import GraphLAM\n",
    "from neural_lam.models.hi_lam import HiLAM\n",
    "from neural_lam.models.hi_lam_parallel import HiLAMParallel\n",
    "from neural_lam.weather_dataset import WeatherDataset\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "# Manually create the args Namespace object with the desired parameters\n",
    "args = argparse.Namespace(\n",
    "    dataset='meps_example',\n",
    "    model='graph_lam',\n",
    "    subset_ds=0,\n",
    "    seed=42,\n",
    "    n_workers=4,\n",
    "    epochs=200,\n",
    "    batch_size=1,\n",
    "    load=None,\n",
    "    restore_opt=0,\n",
    "    precision=32,\n",
    "    graph='1level',\n",
    "    hidden_dim=32,\n",
    "    hidden_layers=1,\n",
    "    processor_layers=1,\n",
    "    mesh_aggr='sum',\n",
    "    output_std=0,\n",
    "    ar_steps=1,\n",
    "    control_only=0,\n",
    "    loss='wmse',\n",
    "    step_length=3,\n",
    "    lr=0.001,\n",
    "    val_interval=1,\n",
    "    eval='test',\n",
    "    n_example_pred=1\n",
    ")\n",
    "\n",
    "print('args', args)\n",
    "print('args', args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(dataset='meps_example', model='graph_lam', subset_ds=0, seed=42, n_workers=4, epochs=200, batch_size=1, load=None, restore_opt=0, precision=32, graph='1level', hidden_dim=32, hidden_layers=1, processor_layers=1, mesh_aggr='sum', output_std=0, ar_steps=1, control_only=0, loss='wmse', step_length=3, lr=0.001, val_interval=1, eval='test', n_example_pred=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 3h67z6h7.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODELS = {\n",
    "    \"graph_lam\": GraphLAM,\n",
    "    \"hi_lam\": HiLAM,\n",
    "    \"hi_lam_parallel\": HiLAMParallel,\n",
    "}\n",
    "\n",
    "\n",
    "# Asserts for arguments\n",
    "assert args.model in MODELS, f\"Unknown model: {args.model}\"\n",
    "assert args.step_length <= 3, \"Too high step length\"\n",
    "assert args.eval in (\n",
    "    None,\n",
    "    \"val\",\n",
    "    \"test\",\n",
    "), f\"Unknown eval setting: {args.eval}\"\n",
    "print('args',args)\n",
    "# Get an (actual) random run id as a unique identifier\n",
    "random_run_id = random.randint(0, 9999)\n",
    "\n",
    "# Set seed\n",
    "seed.seed_everything(args.seed)\n",
    "\n",
    "# Load data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    WeatherDataset(\n",
    "        args.dataset,\n",
    "        pred_length=args.ar_steps,\n",
    "        split=\"train\",\n",
    "        subsample_step=args.step_length,\n",
    "        subset=bool(args.subset_ds),\n",
    "        control_only=args.control_only,\n",
    "    ),\n",
    "    args.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=args.n_workers,\n",
    ")\n",
    "max_pred_length = (65 // args.step_length) - 2  # 19\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    WeatherDataset(\n",
    "        args.dataset,\n",
    "        pred_length=max_pred_length,\n",
    "        split=\"val\",\n",
    "        subsample_step=args.step_length,\n",
    "        subset=bool(args.subset_ds),\n",
    "        control_only=args.control_only,\n",
    "    ),\n",
    "    args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.n_workers,\n",
    ")\n",
    "\n",
    "# Instantiate model + trainer\n",
    "if torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "    torch.set_float32_matmul_precision(\n",
    "        \"high\"\n",
    "    )  # Allows using Tensor Cores on A100s\n",
    "else:\n",
    "    device_name = \"cpu\"\n",
    "\n",
    "# Load model parameters Use new args for model\n",
    "model_class = MODELS[args.model]\n",
    "# if args.load:\n",
    "#     model = model_class.load_from_checkpoint(args.load, args=args)\n",
    "#     if args.restore_opt:\n",
    "#         # Save for later\n",
    "#         # Unclear if this works for multi-GPU\n",
    "#         model.opt_state = torch.load(args.load)[\"optimizer_states\"][0]\n",
    "# else:\n",
    "#     model = model_class(args)\n",
    "\n",
    "prefix = \"subset-\" if args.subset_ds else \"\"\n",
    "if args.eval:\n",
    "    prefix = prefix + f\"eval-{args.eval}-\"\n",
    "run_name = (\n",
    "    f\"{prefix}{args.model}-{args.processor_layers}x{args.hidden_dim}-\"\n",
    "    f\"{time.strftime('%m_%d_%H')}-{random_run_id:04d}\"\n",
    ")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=f\"saved_models/{run_name}\",\n",
    "    filename=\"min_val_loss\",\n",
    "    monitor=\"val_mean_loss\",\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=constants.WANDB_PROJECT, name=run_name, config=args\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=args.epochs,\n",
    "    deterministic=True,\n",
    "    strategy=\"ddp_notebook\",\n",
    "    accelerator=device_name,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    check_val_every_n_epoch=args.val_interval,\n",
    "    precision=args.precision,\n",
    ")\n",
    "\n",
    "# Only init once, on rank 0 only\n",
    "if trainer.global_rank == 0:\n",
    "    utils.init_wandb_metrics(logger)  # Do after wandb.init\n",
    "\n",
    "if args.eval:\n",
    "    if args.eval == \"val\":\n",
    "        eval_loader = val_loader\n",
    "    else:  # Test\n",
    "        eval_loader = torch.utils.data.DataLoader(\n",
    "            WeatherDataset(\n",
    "                args.dataset,\n",
    "                pred_length=max_pred_length,\n",
    "                split=\"test\",\n",
    "                subsample_step=args.step_length,\n",
    "                subset=bool(args.subset_ds),\n",
    "            ),\n",
    "            args.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=args.n_workers,\n",
    "        )\n",
    "\n",
    "    print(f\"Running evaluation on {args.eval}\")\n",
    "    # trainer.test(model=model, dataloaders=eval_loader)\n",
    "else:\n",
    "    # Train model\n",
    "    trainer.fit(\n",
    "        model=model,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=val_loader,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def trace_lightning_model_io_with_loader(model, dataloader):\n",
    "    \"\"\"\n",
    "    Traces the PyTorch Lightning model to get the names of input and output tensors \n",
    "    along with the module hierarchy using a provided DataLoader.\n",
    "\n",
    "    Args:\n",
    "        model (pl.LightningModule): The PyTorch Lightning model to trace.\n",
    "        dataloader (torch.utils.data.DataLoader): The DataLoader to supply inputs to the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are module names and values are tuples of (input_tensor_names, output_tensor_names).\n",
    "    \"\"\"\n",
    "    io_dict = {}\n",
    "    tensor_id_to_name = {}\n",
    "    \n",
    "    def register_hooks(module, module_name):\n",
    "        def hook(module, inputs, outputs):\n",
    "            # Record the inputs\n",
    "            input_names = []\n",
    "            for i, inp in enumerate(inputs):\n",
    "                if isinstance(inp, torch.Tensor):\n",
    "                    tensor_id = id(inp)\n",
    "                    if tensor_id not in tensor_id_to_name:\n",
    "                        tensor_name = f\"{module_name}_input_{i}\"\n",
    "                        tensor_id_to_name[tensor_id] = tensor_name\n",
    "                    else:\n",
    "                        tensor_name = tensor_id_to_name[tensor_id]\n",
    "                    input_names.append(tensor_name)\n",
    "\n",
    "            # Record the outputs\n",
    "            output_names = []\n",
    "            if isinstance(outputs, (tuple, list)):\n",
    "                for i, out in enumerate(outputs):\n",
    "                    if isinstance(out, torch.Tensor):\n",
    "                        tensor_id = id(out)\n",
    "                        tensor_name = f\"{module_name}_output_{i}\"\n",
    "                        tensor_id_to_name[tensor_id] = tensor_name\n",
    "                        output_names.append(tensor_name)\n",
    "            else:\n",
    "                if isinstance(outputs, torch.Tensor):\n",
    "                    tensor_id = id(outputs)\n",
    "                    tensor_name = f\"{module_name}_output_0\"\n",
    "                    tensor_id_to_name[tensor_id] = tensor_name\n",
    "                    output_names.append(tensor_name)\n",
    "\n",
    "            # Store the mapping for this module\n",
    "            io_dict[module_name] = (input_names, output_names)\n",
    "        \n",
    "        module.register_forward_hook(hook)\n",
    "\n",
    "    # Register hooks to all modules\n",
    "    for name, module in model.named_modules():\n",
    "        register_hooks(module, name)\n",
    "\n",
    "    # Perform a forward pass using the dataloader to trigger the hooks\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            model.common_step(batch)  # Trigger forward pass\n",
    "            break  # Only need one batch to trace\n",
    "\n",
    "    return io_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph with 70345 nodes (63784 grid, 6561 mesh)\n",
      "Edges in subgraphs: m2m=51520, g2m=100656, m2g=255136\n",
      "Module: grid_embedder.0\n",
      "  Input Tensors: ['g2m_gnn_output_0']\n",
      "  Output Tensors: ['grid_embedder.0_output_0']\n",
      "Module: grid_embedder.1\n",
      "  Input Tensors: ['grid_embedder.0_output_0']\n",
      "  Output Tensors: ['grid_embedder.1_output_0']\n",
      "Module: grid_embedder.2\n",
      "  Input Tensors: ['grid_embedder.1_output_0']\n",
      "  Output Tensors: ['grid_embedder.2_output_0']\n",
      "Module: grid_embedder.3\n",
      "  Input Tensors: ['grid_embedder.2_output_0']\n",
      "  Output Tensors: ['grid_embedder.3_output_0']\n",
      "Module: grid_embedder\n",
      "  Input Tensors: ['g2m_gnn_output_0']\n",
      "  Output Tensors: ['grid_embedder_output_0']\n",
      "Module: g2m_embedder.0\n",
      "  Input Tensors: ['g2m_embedder.0_input_0']\n",
      "  Output Tensors: ['g2m_embedder.0_output_0']\n",
      "Module: g2m_embedder.1\n",
      "  Input Tensors: ['g2m_embedder.0_output_0']\n",
      "  Output Tensors: ['g2m_embedder.1_output_0']\n",
      "Module: g2m_embedder.2\n",
      "  Input Tensors: ['g2m_embedder.1_output_0']\n",
      "  Output Tensors: ['g2m_embedder.2_output_0']\n",
      "Module: g2m_embedder.3\n",
      "  Input Tensors: ['g2m_embedder.2_output_0']\n",
      "  Output Tensors: ['g2m_embedder.3_output_0']\n",
      "Module: g2m_embedder\n",
      "  Input Tensors: ['g2m_embedder.0_input_0']\n",
      "  Output Tensors: ['g2m_embedder_output_0']\n",
      "Module: m2g_embedder.0\n",
      "  Input Tensors: ['m2g_embedder.0_input_0']\n",
      "  Output Tensors: ['m2g_embedder.0_output_0']\n",
      "Module: m2g_embedder.1\n",
      "  Input Tensors: ['m2g_embedder.0_output_0']\n",
      "  Output Tensors: ['m2g_embedder.1_output_0']\n",
      "Module: m2g_embedder.2\n",
      "  Input Tensors: ['m2g_embedder.1_output_0']\n",
      "  Output Tensors: ['m2g_embedder.2_output_0']\n",
      "Module: m2g_embedder.3\n",
      "  Input Tensors: ['m2g_embedder.2_output_0']\n",
      "  Output Tensors: ['m2g_embedder.3_output_0']\n",
      "Module: m2g_embedder\n",
      "  Input Tensors: ['m2g_embedder.0_input_0']\n",
      "  Output Tensors: ['m2g_embedder_output_0']\n",
      "Module: mesh_embedder.0\n",
      "  Input Tensors: ['mesh_embedder.0_input_0']\n",
      "  Output Tensors: ['mesh_embedder.0_output_0']\n",
      "Module: mesh_embedder.1\n",
      "  Input Tensors: ['mesh_embedder.0_output_0']\n",
      "  Output Tensors: ['mesh_embedder.1_output_0']\n",
      "Module: mesh_embedder.2\n",
      "  Input Tensors: ['mesh_embedder.1_output_0']\n",
      "  Output Tensors: ['mesh_embedder.2_output_0']\n",
      "Module: mesh_embedder.3\n",
      "  Input Tensors: ['mesh_embedder.2_output_0']\n",
      "  Output Tensors: ['mesh_embedder.3_output_0']\n",
      "Module: mesh_embedder\n",
      "  Input Tensors: ['mesh_embedder.0_input_0']\n",
      "  Output Tensors: ['mesh_embedder_output_0']\n",
      "Module: g2m_gnn.edge_mlp.0\n",
      "  Input Tensors: ['mesh_embedder_output_0']\n",
      "  Output Tensors: ['g2m_gnn.edge_mlp.0_output_0']\n",
      "Module: g2m_gnn.edge_mlp.1\n",
      "  Input Tensors: ['g2m_gnn.edge_mlp.0_output_0']\n",
      "  Output Tensors: ['g2m_gnn.edge_mlp.1_output_0']\n",
      "Module: g2m_gnn.edge_mlp.2\n",
      "  Input Tensors: ['g2m_gnn.edge_mlp.1_output_0']\n",
      "  Output Tensors: ['g2m_gnn.edge_mlp.2_output_0']\n",
      "Module: g2m_gnn.edge_mlp.3\n",
      "  Input Tensors: ['g2m_gnn.edge_mlp.2_output_0']\n",
      "  Output Tensors: ['g2m_gnn.edge_mlp.3_output_0']\n",
      "Module: g2m_gnn.edge_mlp\n",
      "  Input Tensors: ['mesh_embedder_output_0']\n",
      "  Output Tensors: ['g2m_gnn.edge_mlp_output_0']\n",
      "Module: g2m_gnn.aggr_module\n",
      "  Input Tensors: ['g2m_gnn.edge_mlp_output_0']\n",
      "  Output Tensors: ['g2m_gnn.aggr_module_output_0']\n",
      "Module: g2m_gnn.aggr_mlp.0\n",
      "  Input Tensors: ['grid_embedder_output_0']\n",
      "  Output Tensors: ['g2m_gnn.aggr_mlp.0_output_0']\n",
      "Module: g2m_gnn.aggr_mlp.1\n",
      "  Input Tensors: ['g2m_gnn.aggr_mlp.0_output_0']\n",
      "  Output Tensors: ['g2m_gnn.aggr_mlp.1_output_0']\n",
      "Module: g2m_gnn.aggr_mlp.2\n",
      "  Input Tensors: ['g2m_gnn.aggr_mlp.1_output_0']\n",
      "  Output Tensors: ['g2m_gnn.aggr_mlp.2_output_0']\n",
      "Module: g2m_gnn.aggr_mlp.3\n",
      "  Input Tensors: ['g2m_gnn.aggr_mlp.2_output_0']\n",
      "  Output Tensors: ['g2m_gnn.aggr_mlp.3_output_0']\n",
      "Module: g2m_gnn.aggr_mlp\n",
      "  Input Tensors: ['grid_embedder_output_0']\n",
      "  Output Tensors: ['g2m_gnn.aggr_mlp_output_0']\n",
      "Module: g2m_gnn\n",
      "  Input Tensors: ['grid_embedder_output_0', 'mesh_embedder_output_0', 'g2m_embedder_output_0']\n",
      "  Output Tensors: ['g2m_gnn_output_0']\n",
      "Module: encoding_grid_mlp.0\n",
      "  Input Tensors: ['grid_embedder_output_0']\n",
      "  Output Tensors: ['encoding_grid_mlp.0_output_0']\n",
      "Module: encoding_grid_mlp.1\n",
      "  Input Tensors: ['encoding_grid_mlp.0_output_0']\n",
      "  Output Tensors: ['encoding_grid_mlp.1_output_0']\n",
      "Module: encoding_grid_mlp.2\n",
      "  Input Tensors: ['encoding_grid_mlp.1_output_0']\n",
      "  Output Tensors: ['encoding_grid_mlp.2_output_0']\n",
      "Module: encoding_grid_mlp.3\n",
      "  Input Tensors: ['encoding_grid_mlp.2_output_0']\n",
      "  Output Tensors: ['encoding_grid_mlp.3_output_0']\n",
      "Module: encoding_grid_mlp\n",
      "  Input Tensors: ['grid_embedder_output_0']\n",
      "  Output Tensors: ['encoding_grid_mlp_output_0']\n",
      "Module: m2m_embedder.0\n",
      "  Input Tensors: ['m2m_embedder.0_input_0']\n",
      "  Output Tensors: ['m2m_embedder.0_output_0']\n",
      "Module: m2m_embedder.1\n",
      "  Input Tensors: ['m2m_embedder.0_output_0']\n",
      "  Output Tensors: ['m2m_embedder.1_output_0']\n",
      "Module: m2m_embedder.2\n",
      "  Input Tensors: ['m2m_embedder.1_output_0']\n",
      "  Output Tensors: ['m2m_embedder.2_output_0']\n",
      "Module: m2m_embedder.3\n",
      "  Input Tensors: ['m2m_embedder.2_output_0']\n",
      "  Output Tensors: ['m2m_embedder.3_output_0']\n",
      "Module: m2m_embedder\n",
      "  Input Tensors: ['m2m_embedder.0_input_0']\n",
      "  Output Tensors: ['m2m_embedder_output_0']\n",
      "Module: processor.module_0.edge_mlp.0\n",
      "  Input Tensors: ['m2g_gnn.aggr_mlp_output_0']\n",
      "  Output Tensors: ['processor.module_0.edge_mlp.0_output_0']\n",
      "Module: processor.module_0.edge_mlp.1\n",
      "  Input Tensors: ['processor.module_0.edge_mlp.0_output_0']\n",
      "  Output Tensors: ['processor.module_0.edge_mlp.1_output_0']\n",
      "Module: processor.module_0.edge_mlp.2\n",
      "  Input Tensors: ['processor.module_0.edge_mlp.1_output_0']\n",
      "  Output Tensors: ['processor.module_0.edge_mlp.2_output_0']\n",
      "Module: processor.module_0.edge_mlp.3\n",
      "  Input Tensors: ['processor.module_0.edge_mlp.2_output_0']\n",
      "  Output Tensors: ['processor.module_0.edge_mlp.3_output_0']\n",
      "Module: processor.module_0.edge_mlp\n",
      "  Input Tensors: ['m2g_gnn.aggr_mlp_output_0']\n",
      "  Output Tensors: ['processor.module_0.edge_mlp_output_0']\n",
      "Module: processor.module_0.aggr_module\n",
      "  Input Tensors: ['processor.module_0.edge_mlp_output_0']\n",
      "  Output Tensors: ['processor.module_0.aggr_module_output_0']\n",
      "Module: processor.module_0.aggr_mlp.0\n",
      "  Input Tensors: ['m2g_gnn.edge_mlp.2_output_0']\n",
      "  Output Tensors: ['processor.module_0.aggr_mlp.0_output_0']\n",
      "Module: processor.module_0.aggr_mlp.1\n",
      "  Input Tensors: ['processor.module_0.aggr_mlp.0_output_0']\n",
      "  Output Tensors: ['processor.module_0.aggr_mlp.1_output_0']\n",
      "Module: processor.module_0.aggr_mlp.2\n",
      "  Input Tensors: ['processor.module_0.aggr_mlp.1_output_0']\n",
      "  Output Tensors: ['processor.module_0.aggr_mlp.2_output_0']\n",
      "Module: processor.module_0.aggr_mlp.3\n",
      "  Input Tensors: ['processor.module_0.aggr_mlp.2_output_0']\n",
      "  Output Tensors: ['processor.module_0.aggr_mlp.3_output_0']\n",
      "Module: processor.module_0.aggr_mlp\n",
      "  Input Tensors: ['m2g_gnn.edge_mlp.2_output_0']\n",
      "  Output Tensors: ['processor.module_0.aggr_mlp_output_0']\n",
      "Module: processor.module_0\n",
      "  Input Tensors: ['g2m_gnn_output_0', 'g2m_gnn_output_0', 'g2m_gnn.aggr_mlp.2_output_0']\n",
      "  Output Tensors: ['processor.module_0_output_0', 'processor.module_0_output_1']\n",
      "Module: processor\n",
      "  Input Tensors: ['g2m_gnn_output_0', 'g2m_gnn.aggr_mlp.2_output_0']\n",
      "  Output Tensors: ['processor_output_0', 'processor_output_1']\n",
      "Module: m2g_gnn.edge_mlp.0\n",
      "  Input Tensors: ['m2m_embedder.2_output_0']\n",
      "  Output Tensors: ['m2g_gnn.edge_mlp.0_output_0']\n",
      "Module: m2g_gnn.edge_mlp.1\n",
      "  Input Tensors: ['m2g_gnn.edge_mlp.0_output_0']\n",
      "  Output Tensors: ['m2g_gnn.edge_mlp.1_output_0']\n",
      "Module: m2g_gnn.edge_mlp.2\n",
      "  Input Tensors: ['m2g_gnn.edge_mlp.1_output_0']\n",
      "  Output Tensors: ['m2g_gnn.edge_mlp.2_output_0']\n",
      "Module: m2g_gnn.edge_mlp.3\n",
      "  Input Tensors: ['m2g_gnn.edge_mlp.2_output_0']\n",
      "  Output Tensors: ['m2g_gnn.edge_mlp.3_output_0']\n",
      "Module: m2g_gnn.edge_mlp\n",
      "  Input Tensors: ['m2m_embedder.2_output_0']\n",
      "  Output Tensors: ['m2g_gnn.edge_mlp_output_0']\n",
      "Module: m2g_gnn.aggr_module\n",
      "  Input Tensors: ['m2g_gnn.edge_mlp_output_0']\n",
      "  Output Tensors: ['m2g_gnn.aggr_module_output_0']\n",
      "Module: m2g_gnn.aggr_mlp.0\n",
      "  Input Tensors: ['m2m_embedder_output_0']\n",
      "  Output Tensors: ['m2g_gnn.aggr_mlp.0_output_0']\n",
      "Module: m2g_gnn.aggr_mlp.1\n",
      "  Input Tensors: ['m2g_gnn.aggr_mlp.0_output_0']\n",
      "  Output Tensors: ['m2g_gnn.aggr_mlp.1_output_0']\n",
      "Module: m2g_gnn.aggr_mlp.2\n",
      "  Input Tensors: ['m2g_gnn.aggr_mlp.1_output_0']\n",
      "  Output Tensors: ['m2g_gnn.aggr_mlp.2_output_0']\n",
      "Module: m2g_gnn.aggr_mlp.3\n",
      "  Input Tensors: ['m2g_gnn.aggr_mlp.2_output_0']\n",
      "  Output Tensors: ['m2g_gnn.aggr_mlp.3_output_0']\n",
      "Module: m2g_gnn.aggr_mlp\n",
      "  Input Tensors: ['m2m_embedder_output_0']\n",
      "  Output Tensors: ['m2g_gnn.aggr_mlp_output_0']\n",
      "Module: m2g_gnn\n",
      "  Input Tensors: ['processor_output_0', 'encoding_grid_mlp.2_output_0', 'g2m_gnn.aggr_mlp.2_output_0']\n",
      "  Output Tensors: ['m2g_gnn_output_0']\n",
      "Module: output_map.0\n",
      "  Input Tensors: ['m2g_gnn_output_0']\n",
      "  Output Tensors: ['output_map.0_output_0']\n",
      "Module: output_map.1\n",
      "  Input Tensors: ['output_map.0_output_0']\n",
      "  Output Tensors: ['output_map.1_output_0']\n",
      "Module: output_map.2\n",
      "  Input Tensors: ['output_map.1_output_0']\n",
      "  Output Tensors: ['output_map.2_output_0']\n",
      "Module: output_map\n",
      "  Input Tensors: ['m2g_gnn_output_0']\n",
      "  Output Tensors: ['output_map_output_0']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_dim = 32\n",
    "hidden_layers = 1\n",
    "mesh_aggr = args.mesh_aggr\n",
    "lr = args.lr\n",
    "dataset = args.dataset\n",
    "output_std = args.output_std\n",
    "loss = args.loss\n",
    "step_length = args.step_length\n",
    "n_example_pred = args.n_example_pred\n",
    "graph = args.graph\n",
    "processor_layers = args.processor_layers\n",
    "model = GraphLAM(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n",
    "\n",
    "model_io = trace_lightning_model_io_with_loader(model, eval_loader)\n",
    "\n",
    "# Print the module I/O information\n",
    "for module_name, (input_names, output_names) in model_io.items():\n",
    "    print(f\"Module: {module_name}\")\n",
    "    print(f\"  Input Tensors: {input_names}\")\n",
    "    print(f\"  Output Tensors: {output_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def plot_model_io_graph(io_dict, output_file='model_io_graph'):\n",
    "    \"\"\"\n",
    "    Plots the model's input/output tensor flow using graphviz.\n",
    "\n",
    "    Args:\n",
    "        io_dict (dict): A dictionary where keys are module names and values are tuples of \n",
    "                        (input_tensor_names, output_tensor_names).\n",
    "        output_file (str): The name of the output file (without extension).\n",
    "\n",
    "    Returns:\n",
    "        Digraph: The generated graph object.\n",
    "    \"\"\"\n",
    "    dot = Digraph(comment='Model I/O Graph')\n",
    "    dot.attr(rankdir='LR', size='10')\n",
    "\n",
    "    for module_name, (input_names, output_names) in io_dict.items():\n",
    "        # Create node for the module\n",
    "        dot.node(module_name, module_name, shape='box')\n",
    "\n",
    "        # Create nodes for inputs\n",
    "        for input_name in input_names:\n",
    "            if input_name not in dot.node_attr:\n",
    "                dot.node(input_name, input_name, shape='ellipse')\n",
    "            dot.edge(input_name, module_name)\n",
    "\n",
    "        # Create nodes for outputs\n",
    "        for output_name in output_names:\n",
    "            if output_name not in dot.node_attr:\n",
    "                dot.node(output_name, output_name, shape='ellipse')\n",
    "            dot.edge(module_name, output_name)\n",
    "\n",
    "    # Save the graph to a file and render it\n",
    "    dot.render(output_file, format='png')\n",
    "\n",
    "    return dot\n",
    "\n",
    "# Example usage:\n",
    "# Assuming model_io is the I/O dictionary generated from the previous step\n",
    "\n",
    "graph = plot_model_io_graph(model_io, output_file='model_io_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def plot_model_io_graph(io_dict, output_file='model_io_graph', format='svg', dpi=300):\n",
    "    \"\"\"\n",
    "    Plots the model's input/output tensor flow using graphviz.\n",
    "\n",
    "    Args:\n",
    "        io_dict (dict): A dictionary where keys are module names and values are tuples of \n",
    "                        (input_tensor_names, output_tensor_names).\n",
    "        output_file (str): The name of the output file (without extension).\n",
    "        format (str): The format of the output file (e.g., 'png', 'svg', 'pdf').\n",
    "        dpi (int): The resolution in dots per inch (DPI) for the output image.\n",
    "\n",
    "    Returns:\n",
    "        Digraph: The generated graph object.\n",
    "    \"\"\"\n",
    "    dot = Digraph(comment='Model I/O Graph')\n",
    "    dot.attr(rankdir='LR', size='10')\n",
    "\n",
    "    for module_name, (input_names, output_names) in io_dict.items():\n",
    "        # Create node for the module\n",
    "        dot.node(module_name, module_name, shape='box')\n",
    "\n",
    "        # Create nodes for inputs\n",
    "        for input_name in input_names:\n",
    "            if input_name not in dot.node_attr:\n",
    "                dot.node(input_name, input_name, shape='ellipse')\n",
    "            dot.edge(input_name, module_name)\n",
    "\n",
    "        # Create nodes for outputs\n",
    "        for output_name in output_names:\n",
    "            if output_name not in dot.node_attr:\n",
    "                dot.node(output_name, output_name, shape='ellipse')\n",
    "            dot.edge(module_name, output_name)\n",
    "\n",
    "    # Set output resolution\n",
    "    dot.attr(dpi=str(dpi))\n",
    "\n",
    "    # Save the graph to a file and render it\n",
    "    dot.render(output_file, format=format)\n",
    "\n",
    "    return dot\n",
    "\n",
    "# Example usage:\n",
    "# Assuming model_io is the I/O dictionary generated from the previous step\n",
    "\n",
    "graph = plot_model_io_graph(model_io, output_file='model_io_graph', format='png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def plot_simplified_model_io_graph(io_dict, output_file='simplified_model_io_graph', format='png', dpi=300):\n",
    "    \"\"\"\n",
    "    Plots a simplified version of the model's input/output tensor flow using graphviz.\n",
    "    \n",
    "    Args:\n",
    "        io_dict (dict): A dictionary where keys are module names and values are tuples of \n",
    "                        (input_tensor_names, output_tensor_names).\n",
    "        output_file (str): The name of the output file (without extension).\n",
    "        format (str): The format of the output file (e.g., 'png', 'svg', 'pdf').\n",
    "        dpi (int): The resolution in dots per inch (DPI) for the output image.\n",
    "    \n",
    "    Returns:\n",
    "        Digraph: The generated graph object.\n",
    "    \"\"\"\n",
    "    dot = Digraph(comment='Simplified Model I/O Graph')\n",
    "    dot.attr(rankdir='TB', size='10')  # TB for top-bottom layout, LR for left-right\n",
    "\n",
    "    # Track unique tensors and simplify connections\n",
    "    tensor_seen = set()\n",
    "\n",
    "    for module_name, (input_names, output_names) in io_dict.items():\n",
    "        # Create a node for the module\n",
    "        dot.node(module_name, module_name, shape='box')\n",
    "\n",
    "        # Only show unique input tensors to avoid clutter\n",
    "        for input_name in input_names:\n",
    "            if input_name not in tensor_seen:\n",
    "                dot.node(input_name, input_name, shape='ellipse')\n",
    "                tensor_seen.add(input_name)\n",
    "            dot.edge(input_name, module_name)\n",
    "\n",
    "        # Only show unique output tensors to avoid clutter\n",
    "        for output_name in output_names:\n",
    "            if output_name not in tensor_seen:\n",
    "                dot.node(output_name, output_name, shape='ellipse')\n",
    "                tensor_seen.add(output_name)\n",
    "            dot.edge(module_name, output_name)\n",
    "\n",
    "    # Set output resolution\n",
    "    dot.attr(dpi=str(dpi))\n",
    "\n",
    "    # Save the graph to a file and render it\n",
    "    dot.render(output_file, format=format)\n",
    "\n",
    "    return dot\n",
    "\n",
    "# Example usage:\n",
    "# Assuming model_io is the I/O dictionary generated from the previous step\n",
    "\n",
    "graph = plot_simplified_model_io_graph(model_io, output_file='simplified_model_io_graph', format='png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph with 70345 nodes (63784 grid, 6561 mesh)\n",
      "Edges in subgraphs: m2m=51520, g2m=100656, m2g=255136\n",
      "Loaded graph with 70345 nodes (63784 grid, 6561 mesh)\n",
      "Edges in subgraphs: m2m=51520, g2m=100656, m2g=255136\n",
      "Module: grid_embedder\n",
      "  Input Tensor: g2m_gnn_output_0\n",
      "  Output Tensor: grid_embedder_output_0\n",
      "Module: g2m_embedder\n",
      "  Input Tensor: g2m_embedder_input_0\n",
      "  Output Tensor: g2m_embedder_output_0\n",
      "Module: m2g_embedder\n",
      "  Input Tensor: m2g_embedder_input_0\n",
      "  Output Tensor: m2g_embedder_output_0\n",
      "Module: mesh_embedder\n",
      "  Input Tensor: mesh_embedder_input_0\n",
      "  Output Tensor: mesh_embedder_output_0\n",
      "Module: g2m_gnn\n",
      "  Input Tensor: grid_embedder_output_0\n",
      "  Input Tensor: grid_embedder_output_0\n",
      "  Input Tensor: output_map_output_0\n",
      "  Output Tensor: g2m_gnn_output_0\n",
      "Module: encoding_grid_mlp\n",
      "  Input Tensor: grid_embedder_output_0\n",
      "  Output Tensor: encoding_grid_mlp_output_0\n",
      "Module: m2m_embedder\n",
      "  Input Tensor: m2m_embedder_input_0\n",
      "  Output Tensor: m2m_embedder_output_0\n",
      "Module: processor\n",
      "  Input Tensor: g2m_gnn_output_0\n",
      "  Input Tensor: processor_output_1\n",
      "  Output Tensor: processor_output_0\n",
      "  Output Tensor: processor_output_1\n",
      "Module: m2g_gnn\n",
      "  Input Tensor: processor_output_0\n",
      "  Input Tensor: output_map_output_0\n",
      "  Input Tensor: processor_output_1\n",
      "  Output Tensor: m2g_gnn_output_0\n",
      "Module: output_map\n",
      "  Input Tensor: m2g_gnn_output_0\n",
      "  Output Tensor: output_map_output_0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from graphviz import Digraph\n",
    "\n",
    "def plot_simplified_model_io_graph(io_dict, output_file='simplified_model_io_graph', format='png', dpi=300):\n",
    "    \"\"\"\n",
    "    Plots a simplified version of the model's input/output tensor flow using graphviz.\n",
    "    \n",
    "    Args:\n",
    "        io_dict (dict): A dictionary where keys are module names and values are tuples of \n",
    "                        (input_tensor_names, output_tensor_names).\n",
    "        output_file (str): The name of the output file (without extension).\n",
    "        format (str): The format of the output file (e.g., 'png', 'svg', 'pdf').\n",
    "        dpi (int): The resolution in dots per inch (DPI) for the output image.\n",
    "    \n",
    "    Returns:\n",
    "        Digraph: The generated graph object.\n",
    "    \"\"\"\n",
    "    dot = Digraph(comment='Simplified Model I/O Graph')\n",
    "    dot.attr(rankdir='TB', size='10')  # TB for top-bottom layout\n",
    "\n",
    "    # Track unique tensors and simplify connections\n",
    "    tensor_seen = set()\n",
    "\n",
    "    for module_name, (input_names, output_names) in io_dict.items():\n",
    "        # Extract the top-level module name only\n",
    "        top_level_module_name = module_name.split('.')[0]\n",
    "\n",
    "        # Create a node for the top-level module\n",
    "        if top_level_module_name not in dot.node_attr:\n",
    "            dot.node(top_level_module_name, top_level_module_name, shape='box')\n",
    "\n",
    "        # Only show unique input tensors to avoid clutter\n",
    "        for input_name in input_names:\n",
    "            if input_name not in tensor_seen:\n",
    "                tensor_seen.add(input_name)\n",
    "                dot.node(input_name, input_name, shape='ellipse')\n",
    "            dot.edge(input_name, top_level_module_name)\n",
    "\n",
    "        # Only show unique output tensors to avoid clutter\n",
    "        for output_name in output_names:\n",
    "            if output_name not in tensor_seen:\n",
    "                tensor_seen.add(output_name)\n",
    "                dot.node(output_name, output_name, shape='ellipse')\n",
    "            dot.edge(top_level_module_name, output_name)\n",
    "\n",
    "    # Set output resolution\n",
    "    dot.attr(dpi=str(dpi))\n",
    "\n",
    "    # Save the graph to a file and render it\n",
    "    dot.render(output_file, format=format)\n",
    "\n",
    "    return dot\n",
    "\n",
    "def trace_lightning_model_io_with_loader(model, dataloader):\n",
    "    \"\"\"\n",
    "    Traces the PyTorch Lightning model to get the names of input and output tensors \n",
    "    along with the module hierarchy using a provided DataLoader.\n",
    "\n",
    "    Args:\n",
    "        model (pl.LightningModule): The PyTorch Lightning model to trace.\n",
    "        dataloader (torch.utils.data.DataLoader): The DataLoader to supply inputs to the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are module names and values are tuples of (input_tensor_names, output_tensor_names).\n",
    "    \"\"\"\n",
    "    io_dict = {}\n",
    "    tensor_id_to_name = {}\n",
    "    \n",
    "    def register_hooks(module, module_name):\n",
    "        def hook(module, inputs, outputs):\n",
    "            # Capture the top-level module name\n",
    "            top_level_module_name = module_name.split('.')[0]\n",
    "            # Record the inputs\n",
    "            input_names = []\n",
    "            for i, inp in enumerate(inputs):\n",
    "                if isinstance(inp, torch.Tensor):\n",
    "                    tensor_id = id(inp)\n",
    "                    if tensor_id not in tensor_id_to_name:\n",
    "                        tensor_name = f\"{top_level_module_name}_input_{i}\"\n",
    "                        tensor_id_to_name[tensor_id] = tensor_name\n",
    "                    else:\n",
    "                        tensor_name = tensor_id_to_name[tensor_id]\n",
    "                    input_names.append(tensor_name)\n",
    "\n",
    "            # Record the outputs\n",
    "            output_names = []\n",
    "            if isinstance(outputs, (tuple, list)):\n",
    "                for i, out in enumerate(outputs):\n",
    "                    if isinstance(out, torch.Tensor):\n",
    "                        tensor_id = id(out)\n",
    "                        tensor_name = f\"{top_level_module_name}_output_{i}\"\n",
    "                        tensor_id_to_name[tensor_id] = tensor_name\n",
    "                        output_names.append(tensor_name)\n",
    "            else:\n",
    "                if isinstance(outputs, torch.Tensor):\n",
    "                    tensor_id = id(outputs)\n",
    "                    tensor_name = f\"{top_level_module_name}_output_0\"\n",
    "                    tensor_id_to_name[tensor_id] = tensor_name\n",
    "                    output_names.append(tensor_name)\n",
    "\n",
    "            # Store the mapping for this module\n",
    "            io_dict[top_level_module_name] = (input_names, output_names)\n",
    "        \n",
    "        module.register_forward_hook(hook)\n",
    "\n",
    "    # Register hooks to top-level modules only\n",
    "    for name, module in model.named_children():\n",
    "        register_hooks(module, name)\n",
    "\n",
    "    # Perform a forward pass using the dataloader to trigger the hooks\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            model.common_step(batch)  # Trigger forward pass\n",
    "            break  # Only need one batch to trace\n",
    "\n",
    "    return io_dict\n",
    "\n",
    "\n",
    "\n",
    "hidden_dim = 32\n",
    "hidden_layers = 1\n",
    "mesh_aggr = args.mesh_aggr\n",
    "lr = args.lr\n",
    "dataset = args.dataset\n",
    "output_std = args.output_std\n",
    "loss = args.loss\n",
    "step_length = args.step_length\n",
    "n_example_pred = args.n_example_pred\n",
    "graph = args.graph\n",
    "processor_layers = args.processor_layers\n",
    "model = GraphLAM(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n",
    "\n",
    "\n",
    "\n",
    "model = GraphLAM(hidden_dim, hidden_layers, mesh_aggr, lr, dataset, output_std, loss, step_length, n_example_pred, graph, processor_layers)\n",
    "\n",
    "# Assuming eval_loader is your DataLoader\n",
    "# eval_loader = torch.utils.data.DataLoader(...)  # Set up your DataLoader\n",
    "\n",
    "# Trace the model I/O\n",
    "model_io = trace_lightning_model_io_with_loader(model, eval_loader)\n",
    "\n",
    "# Plot the simplified model I/O graph\n",
    "graph = plot_simplified_model_io_graph(model_io, output_file='simplified_model_io_graph', format='png', dpi=300)\n",
    "\n",
    "# Print the module I/O information in the desired format\n",
    "for module_name, (input_names, output_names) in model_io.items():\n",
    "    print(f\"Module: {module_name}\")\n",
    "    for input_name in input_names:\n",
    "        print(f\"  Input Tensor: {input_name}\")\n",
    "    for output_name in output_names:\n",
    "        print(f\"  Output Tensor: {output_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/aw1223/ip/agile/\")\n",
    "\n",
    "from sdk.ample import Ample\n",
    "\n",
    "\n",
    "from sdk.graph_tracer import ManualGraphInspector\n",
    "tracer = ManualGraphInspector(model)\n",
    "# tracer.get_input_output_layers()\n",
    "# # tracer.print_input_output_layers()\n",
    "# tracer.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MLP_Model(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "  )\n",
      ")\n",
      "layers ModuleList(\n",
      "  (0): Linear(in_features=32, out_features=32, bias=True)\n",
      ")\n",
      "layers.0 Linear(in_features=32, out_features=32, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# To inspect the whole model structure and its modules\n",
    "for name, module in model.named_modules():\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MLP_Model.forward() missing 1 required positional argument: 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m minimal_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adjust the dimensions to match what your model expects\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Trace the model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimal_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Generate the visualization\u001b[39;00m\n\u001b[1;32m     12\u001b[0m make_dot(traced_model\u001b[38;5;241m.\u001b[39mgraph, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m.\u001b[39mnamed_parameters()))\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/jit/_trace.py:820\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m ):\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/jit/_trace.py:1088\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1088\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/nn/modules/module.py:1522\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[0;31mTypeError\u001b[0m: MLP_Model.forward() missing 1 required positional argument: 'edge_index'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Example of using minimal data for tracing\n",
    "# You can use a small tensor with minimal dimensions if you want to keep it simple\n",
    "minimal_input = torch.randn(1, 1, 1)  # Adjust the dimensions to match what your model expects\n",
    "\n",
    "# Trace the model\n",
    "traced_model = torch.jit.trace(model, minimal_input)\n",
    "\n",
    "# Generate the visualization\n",
    "make_dot(traced_model.graph, params=dict(model.named_parameters())).render(\"model_graph\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_num_mesh\n",
      "Loaded graph with 70345 nodes (63784 grid, 6561 mesh)\n",
      "input_dim 32\n",
      "hidden_dim 32\n",
      "hidden_layers 1\n",
      "input_dim 32\n",
      "hidden_dim 32\n",
      "hidden_layers 1\n",
      "Edges in subgraphs: m2m=51520, g2m=100656, m2g=255136\n",
      "input_dim 32\n",
      "hidden_dim 32\n",
      "hidden_layers 1\n",
      "stage1\n",
      "stage2\n"
     ]
    },
    {
     "ename": "TraceError",
     "evalue": "Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adjust to match your model's input shape\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Use torch.fx to trace the model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# traced_model = torch.fx.symbolic_trace(model)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymbolic_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Print the graph representation\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print(traced_model.graph)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Optionally visualize the graph (requires graphviz)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphModule\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/fx/_symbolic_trace.py:1193\u001b[0m, in \u001b[0;36msymbolic_trace\u001b[0;34m(root, concrete_args)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;124;03mSymbolic tracing API\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    GraphModule: a Module created from the recorded operations from ``root``.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m tracer \u001b[38;5;241m=\u001b[39m Tracer()\n\u001b[0;32m-> 1193\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1195\u001b[0m     root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(root, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;28;01melse\u001b[39;00m root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   1196\u001b[0m )\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _make_graph_module(tracer\u001b[38;5;241m.\u001b[39mroot, graph, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/fx/_symbolic_trace.py:793\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_search:\n\u001b[1;32m    787\u001b[0m             _autowrap_check(\n\u001b[1;32m    788\u001b[0m                 patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    789\u001b[0m             )\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    791\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 793\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m),),\n\u001b[1;32m    794\u001b[0m             {},\n\u001b[1;32m    795\u001b[0m             type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/pytorch_lightning/core/module.py\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/fx/proxy.py:412\u001b[0m, in \u001b[0;36mProxy.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNPACK_SEQUENCE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(inst\u001b[38;5;241m.\u001b[39margval))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/fx/proxy.py:312\u001b[0m, in \u001b[0;36mTracerBase.iter\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[1;32m    307\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called when a proxy object is being iterated over, such as\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    when used in control flow.  Normally we don't know what to do because\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    we don't know the value of the proxy, but a custom tracer can attach more\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    information to the graph node using create_node and can choose to return an iterator.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraceError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy object cannot be iterated. This can be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    313\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattempted when the Proxy is used in a loop or\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    314\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as a *args or **kwargs function argument. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    315\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the torch.fx docs on pytorch.org for a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    316\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmore detailed explanation of what types of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    317\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrol flow can be traced, and check out the\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    318\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Proxy docstring for help troubleshooting \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    319\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy iteration errors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTraceError\u001b[0m: Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx\n",
    "\n",
    "# Assuming GraphLAM is defined as shown before\n",
    "# and has a proper forward method\n",
    "\n",
    "# Instantiate your model\n",
    "hidden_dim = args.hidden_dim\n",
    "hidden_layers = args.hidden_layers\n",
    "mesh_aggr = args.mesh_aggr\n",
    "lr = args.lr\n",
    "dataset = args.dataset\n",
    "output_std = args.output_std\n",
    "loss = args.loss\n",
    "step_length = args.step_length\n",
    "n_example_pred = args.n_example_pred\n",
    "graph = args.graph\n",
    "processor_layers = args.processor_layers\n",
    "model = GraphLAM(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n",
    "\n",
    "# Create an input that matches the expected input shape\n",
    "dummy_input = torch.randn(1, 1, 1)  # Adjust to match your model's input shape\n",
    "\n",
    "# Use torch.fx to trace the model\n",
    "# traced_model = torch.fx.symbolic_trace(model)\n",
    "traced_model = torch.fx.symbolic_trace(model)\n",
    "# Print the graph representation\n",
    "# print(traced_model.graph)\n",
    "\n",
    "# Optionally visualize the graph (requires graphviz)\n",
    "from torch.fx import GraphModule\n",
    "from torch.fx.graph import Graph\n",
    "from torch.fx.graph_module import GraphModule\n",
    "\n",
    "def visualize_fx_graph(traced: GraphModule, input_shape: torch.Size):\n",
    "    dummy_input = torch.randn(input_shape)\n",
    "    dot = make_dot(traced(dummy_input), params=dict(traced.named_parameters()))\n",
    "    dot.render(\"traced_model_graph\", format=\"png\")\n",
    "\n",
    "# Visualize the traced graph (provide the correct input shape)\n",
    "visualize_fx_graph(traced_model, input_shape=(1, 1, 1))  # Adjust input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TraceError",
     "evalue": "Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Trace using the custom tracer\u001b[39;00m\n\u001b[1;32m     12\u001b[0m tracer \u001b[38;5;241m=\u001b[39m CustomTracer()\n\u001b[0;32m---> 13\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create a GraphModule from the traced graph\u001b[39;00m\n\u001b[1;32m     16\u001b[0m graph_module \u001b[38;5;241m=\u001b[39m fx\u001b[38;5;241m.\u001b[39mGraphModule(model, traced_model)\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/fx/_symbolic_trace.py:793\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_search:\n\u001b[1;32m    787\u001b[0m             _autowrap_check(\n\u001b[1;32m    788\u001b[0m                 patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    789\u001b[0m             )\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    791\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 793\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m),),\n\u001b[1;32m    794\u001b[0m             {},\n\u001b[1;32m    795\u001b[0m             type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/pytorch_lightning/core/module.py\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/fx/proxy.py:412\u001b[0m, in \u001b[0;36mProxy.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNPACK_SEQUENCE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(inst\u001b[38;5;241m.\u001b[39margval))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/fx/proxy.py:312\u001b[0m, in \u001b[0;36mTracerBase.iter\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[1;32m    307\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called when a proxy object is being iterated over, such as\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    when used in control flow.  Normally we don't know what to do because\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    we don't know the value of the proxy, but a custom tracer can attach more\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    information to the graph node using create_node and can choose to return an iterator.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraceError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy object cannot be iterated. This can be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    313\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattempted when the Proxy is used in a loop or\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    314\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as a *args or **kwargs function argument. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    315\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the torch.fx docs on pytorch.org for a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    316\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmore detailed explanation of what types of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    317\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrol flow can be traced, and check out the\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    318\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Proxy docstring for help troubleshooting \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    319\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy iteration errors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTraceError\u001b[0m: Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx as fx\n",
    "\n",
    "class CustomTracer(fx.Tracer):\n",
    "    def is_leaf_module(self, m: torch.nn.Module, module_qualified_name: str) -> bool:\n",
    "        # Treat InteractionNet as a leaf module (don't trace into it)\n",
    "        if isinstance(m, InteractionNet):\n",
    "            return True\n",
    "        return super().is_leaf_module(m, module_qualified_name)\n",
    "\n",
    "# Trace using the custom tracer\n",
    "tracer = CustomTracer()\n",
    "traced_model = tracer.trace(model)\n",
    "\n",
    "# Create a GraphModule from the traced graph\n",
    "graph_module = fx.GraphModule(model, traced_model)\n",
    "\n",
    "# Print or visualize the traced graph\n",
    "print(graph_module.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_num_mesh\n",
      "Loaded graph with 70345 nodes (63784 grid, 6561 mesh)\n",
      "input_dim 32\n",
      "hidden_dim 32\n",
      "hidden_layers 1\n",
      "input_dim 32\n",
      "hidden_dim 32\n",
      "hidden_layers 1\n",
      "Edges in subgraphs: m2m=51520, g2m=100656, m2g=255136\n",
      "input_dim 32\n",
      "hidden_dim 32\n",
      "hidden_layers 1\n",
      "stage1\n",
      "stage2\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Module [GraphLAM] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m edge_rep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m16\u001b[39m))  \u001b[38;5;66;03m# Example tensor, adjust dimensions based on model requirements\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msend_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrec_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_rep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Visualize the computational graph using torchviz\u001b[39;00m\n\u001b[1;32m     40\u001b[0m dot \u001b[38;5;241m=\u001b[39m make_dot(output, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m.\u001b[39mnamed_parameters()))\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/pytorch_lightning/core/module.py:691\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    681\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Same as :meth:`torch.nn.Module.forward`.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ample/lib/python3.11/site-packages/torch/nn/modules/module.py:351\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [GraphLAM] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch.utils.data\n",
    "import torch.fx as fx\n",
    "import pytorch_lightning as pl\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Setting seed for reproducibility\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "\n",
    "hidden_dim = args.hidden_dim\n",
    "hidden_layers = args.hidden_layers\n",
    "mesh_aggr = args.mesh_aggr\n",
    "lr = args.lr\n",
    "dataset = args.dataset\n",
    "output_std = args.output_std\n",
    "loss = args.loss\n",
    "step_length = args.step_length\n",
    "n_example_pred = args.n_example_pred\n",
    "graph = args.graph\n",
    "processor_layers = args.processor_layers\n",
    "# model = GraphLAM(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n",
    "\n",
    "# Instantiate model\n",
    "model_class = MODELS[args.model]\n",
    "model = model_class(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n",
    "\n",
    "# Create dummy inputs for visualization\n",
    "# This will depend on the input requirements of the model, adjust accordingly\n",
    "send_rep = torch.randn((2, 10, 16))  # Example tensor, adjust dimensions based on model requirements\n",
    "rec_rep = torch.randn((2, 10, 16))   # Example tensor, adjust dimensions based on model requirements\n",
    "edge_rep = torch.randn((2, 10, 16))  # Example tensor, adjust dimensions based on model requirements\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(send_rep, rec_rep, edge_rep)\n",
    "\n",
    "# Visualize the computational graph using torchviz\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.render(\"model_graph\", format=\"png\")\n",
    "\n",
    "# If torch.fx is preferred for tracing\n",
    "traced_model = fx.symbolic_trace(model)\n",
    "print(traced_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GraphLAM\n",
      "grid_embedder (Sequential)\n",
      "    0 (Linear)\n",
      "    1 (SiLU)\n",
      "    2 (Linear)\n",
      "    3 (LayerNorm)\n",
      "g2m_embedder (Sequential)\n",
      "    0 (Linear)\n",
      "    1 (SiLU)\n",
      "    2 (Linear)\n",
      "    3 (LayerNorm)\n",
      "m2g_embedder (Sequential)\n",
      "    0 (Linear)\n",
      "    1 (SiLU)\n",
      "    2 (Linear)\n",
      "    3 (LayerNorm)\n",
      "g2m_gnn (InteractionNetWrapper)\n",
      "    interaction_net (InteractionNet)\n",
      "        aggr_module (SumAggregation)\n",
      "        edge_mlp (Sequential)\n",
      "            0 (Linear)\n",
      "            1 (SiLU)\n",
      "            2 (Linear)\n",
      "            3 (LayerNorm)\n",
      "        aggr_mlp (Sequential)\n",
      "            0 (Linear)\n",
      "            1 (SiLU)\n",
      "            2 (Linear)\n",
      "            3 (LayerNorm)\n",
      "encoding_grid_mlp (Sequential)\n",
      "    0 (Linear)\n",
      "    1 (SiLU)\n",
      "    2 (Linear)\n",
      "    3 (LayerNorm)\n",
      "m2g_gnn (InteractionNetWrapper)\n",
      "    interaction_net (InteractionNet)\n",
      "        aggr_module (SumAggregation)\n",
      "        edge_mlp (Sequential)\n",
      "            0 (Linear)\n",
      "            1 (SiLU)\n",
      "            2 (Linear)\n",
      "            3 (LayerNorm)\n",
      "        aggr_mlp (Sequential)\n",
      "            0 (Linear)\n",
      "            1 (SiLU)\n",
      "            2 (Linear)\n",
      "            3 (LayerNorm)\n",
      "output_map (Sequential)\n",
      "    0 (Linear)\n",
      "    1 (SiLU)\n",
      "    2 (Linear)\n",
      "mesh_embedder (Sequential)\n",
      "    0 (Linear)\n",
      "    1 (SiLU)\n",
      "    2 (Linear)\n",
      "    3 (LayerNorm)\n",
      "m2m_embedder (Sequential)\n",
      "    0 (Linear)\n",
      "    1 (SiLU)\n",
      "    2 (Linear)\n",
      "    3 (LayerNorm)\n",
      "processor (Sequential)\n",
      "    module_0 (InteractionNetWrapper)\n",
      "        interaction_net (InteractionNet)\n",
      "            aggr_module (SumAggregation)\n",
      "            edge_mlp (Sequential)\n",
      "                0 (Linear)\n",
      "                1 (SiLU)\n",
      "                2 (Linear)\n",
      "                3 (LayerNorm)\n",
      "            aggr_mlp (Sequential)\n",
      "                0 (Linear)\n",
      "                1 (SiLU)\n",
      "                2 (Linear)\n",
      "                3 (LayerNorm)\n"
     ]
    }
   ],
   "source": [
    "def trace_model_connections(model):\n",
    "    def recurse(obj, depth=0):\n",
    "        indent = \"    \" * depth\n",
    "        if hasattr(obj, 'modules'):\n",
    "            for name, module in obj.named_children():\n",
    "                if list(module.children()):  # Check if module has children\n",
    "                    print(f\"{indent}{name} ({module.__class__.__name__})\")\n",
    "                    recurse(module, depth + 1)\n",
    "                else:\n",
    "                    print(f\"{indent}{name} ({module.__class__.__name__})\")\n",
    "        elif hasattr(obj, '__call__'):\n",
    "            print(f\"{indent}{obj.__class__.__name__}\")\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    recurse(model)\n",
    "\n",
    "# Assuming `model` is instantiated and provided as an instance of a class like GraphLAM\n",
    "trace_model_connections(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of numpy.core.multiarray failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/multiarray.py\", line 1, in <module>\n",
      "    from numpy._core import multiarray\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core.fromnumeric failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\n",
      "]\n",
      "[autoreload of numpy.core.arrayprint failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core.numeric failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\n",
      "]\n",
      "[autoreload of numpy.core.records failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core.getlimits failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core._internal failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/_internal.py\", line 1, in <module>\n",
      "    from numpy._core import _internal\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/_internal.py\", line 13, in <module>\n",
      "    from .multiarray import dtype, array, ndarray, promote_types, StringDType\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.core failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\n",
      "]\n",
      "[autoreload of numpy.lib.mixins failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\n",
      "]\n",
      "[autoreload of numpy.lib.scimath failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/numerictypes.py\", line 2, in __getattr__\n",
      "    from numpy._core import numerictypes\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib.stride_tricks failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/stride_tricks.py\", line 1, in <module>\n",
      "    from ._stride_tricks_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_stride_tricks_impl.py\", line 14, in <module>\n",
      "    from numpy._core.numeric import normalize_axis_tuple\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numeric.py\", line 11, in <module>\n",
      "    from . import multiarray\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_typing/_scalars.py:12: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  _BoolLike_co = Union[bool, np.bool]\n",
      "[autoreload of numpy._typing._scalars failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_typing/_scalars.py\", line 12, in <module>\n",
      "    _BoolLike_co = Union[bool, np.bool]\n",
      "                               ^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/__init__.py\", line 324, in __getattr__\n",
      "    # Warn for expired attributes\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "]\n",
      "/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_typing/_dtype_like.py:142: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  type[np.bool],\n",
      "[autoreload of numpy._typing._dtype_like failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_typing/_dtype_like.py\", line 142, in <module>\n",
      "    type[np.bool],\n",
      "         ^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/__init__.py\", line 324, in __getattr__\n",
      "    # Warn for expired attributes\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "]\n",
      "/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_typing/_array_like.py:97: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  dtype[np.bool],\n",
      "[autoreload of numpy._typing._array_like failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_typing/_array_like.py\", line 97, in <module>\n",
      "    dtype[np.bool],\n",
      "          ^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/__init__.py\", line 324, in __getattr__\n",
      "    # Warn for expired attributes\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "]\n",
      "[autoreload of numpy.linalg failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/linalg/linalg.py\", line 3, in __getattr__\n",
      "    from numpy.linalg import _linalg\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/linalg/_linalg.py\", line 25, in <module>\n",
      "    from numpy._core import (\n",
      "ImportError: cannot import name 'array' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.matrixlib.defmatrix failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/matrixlib/defmatrix.py\", line 8, in <module>\n",
      "    import numpy._core.numeric as N\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numeric.py\", line 11, in <module>\n",
      "    from . import multiarray\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib.format failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/format.py\", line 170, in <module>\n",
      "    from numpy.lib._utils_impl import drop_metadata\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_utils_impl.py\", line 10, in <module>\n",
      "    from numpy._core import ndarray\n",
      "ImportError: cannot import name 'ndarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.lib._iotools failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_iotools.py\", line 7, in <module>\n",
      "    import numpy._core.numeric as nx\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numeric.py\", line 11, in <module>\n",
      "    from . import multiarray\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib.npyio failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/npyio.py\", line 1, in <module>\n",
      "    from ._npyio_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_npyio_impl.py\", line 20, in <module>\n",
      "    from numpy._core.multiarray import packbits, unpackbits\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/__init__.py\", line 13, in <module>\n",
      "    from . import array_utils\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.fft._pocketfft failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/fft/_pocketfft.py\", line 36, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.fft failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/fft/helper.py\", line 3, in __getattr__\n",
      "    from numpy.fft import _helper\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/fft/_helper.py\", line 5, in <module>\n",
      "    from numpy._core import integer, empty, arange, asarray, roll\n",
      "ImportError: cannot import name 'integer' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.polyutils failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/polynomial/polyutils.py\", line 27, in <module>\n",
      "    from numpy._core.multiarray import dragon4_positional, dragon4_scientific\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.polynomial.polynomial failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/polynomial/polynomial.py\", line 85, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.chebyshev failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/polynomial/chebyshev.py\", line 112, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.legendre failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/polynomial/legendre.py\", line 84, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.hermite failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/polynomial/hermite.py\", line 80, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.hermite_e failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/polynomial/hermite_e.py\", line 80, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.polynomial.laguerre failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/polynomial/laguerre.py\", line 80, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.ctypeslib failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/ctypeslib.py\", line 59, in <module>\n",
      "    from numpy._core.multiarray import _flagdict, flagsobj\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy.ma.core failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/umath.py\", line 2, in __getattr__\n",
      "    from numpy._core import umath\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/umath.py\", line 15, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_get_extobj_dict' from 'numpy.core._multiarray_umath' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\n",
      "]\n",
      "[autoreload of numpy.ma.extras failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/ma/extras.py\", line 35, in <module>\n",
      "    from numpy.lib.array_utils import normalize_axis_index, normalize_axis_tuple\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/array_utils.py\", line 1, in <module>\n",
      "    from ._array_utils_impl import (\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/lib/_array_utils_impl.py\", line 4, in <module>\n",
      "    from numpy._core import asarray\n",
      "ImportError: cannot import name 'asarray' from 'numpy._core' (/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py)\n",
      "]\n",
      "[autoreload of numpy failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    if not append_obj(module, old_objects, name, obj):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 423, in append_obj\n",
      "    in_module = hasattr(obj, \"__module__\") and obj.__module__ == module.__name__\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/core/defchararray.py\", line 2, in __getattr__\n",
      "    from numpy._core import defchararray\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/defchararray.py\", line 21, in <module>\n",
      "    from .numerictypes import bytes_, str_, character\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/numerictypes.py\", line 82, in <module>\n",
      "    from . import multiarray as ma\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n",
      "[autoreload of numpy._core failed: Traceback (most recent call last):\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/__init__.py\", line 23, in <module>\n",
      "    from . import multiarray\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/multiarray.py\", line 83, in <module>\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 178, in decorator\n",
      "    return array_function_dispatch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aw1223/anaconda3/envs/ample/lib/python3.11/site-packages/numpy/_core/overrides.py\", line 158, in decorator\n",
      "    add_docstring(implementation, dispatcher.__doc__)\n",
      "RuntimeError: empty_like method already has a different docstring\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_embedder: ['grid_embedder.0', 'grid_embedder.1', 'grid_embedder.2', 'grid_embedder.3']\n",
      "g2m_embedder: ['g2m_embedder.0', 'g2m_embedder.1', 'g2m_embedder.2', 'g2m_embedder.3']\n",
      "m2g_embedder: ['m2g_embedder.0', 'm2g_embedder.1', 'm2g_embedder.2', 'm2g_embedder.3']\n",
      "g2m_gnn.interaction_net: ['g2m_gnn.interaction_net.aggr_module']\n",
      "g2m_gnn.interaction_net.edge_mlp: ['g2m_gnn.interaction_net.edge_mlp.0', 'g2m_gnn.interaction_net.edge_mlp.1', 'g2m_gnn.interaction_net.edge_mlp.2', 'g2m_gnn.interaction_net.edge_mlp.3']\n",
      "g2m_gnn.interaction_net.aggr_mlp: ['g2m_gnn.interaction_net.aggr_mlp.0', 'g2m_gnn.interaction_net.aggr_mlp.1', 'g2m_gnn.interaction_net.aggr_mlp.2', 'g2m_gnn.interaction_net.aggr_mlp.3']\n",
      "encoding_grid_mlp: ['encoding_grid_mlp.0', 'encoding_grid_mlp.1', 'encoding_grid_mlp.2', 'encoding_grid_mlp.3']\n",
      "m2g_gnn.interaction_net: ['m2g_gnn.interaction_net.aggr_module']\n",
      "m2g_gnn.interaction_net.edge_mlp: ['m2g_gnn.interaction_net.edge_mlp.0', 'm2g_gnn.interaction_net.edge_mlp.1', 'm2g_gnn.interaction_net.edge_mlp.2', 'm2g_gnn.interaction_net.edge_mlp.3']\n",
      "m2g_gnn.interaction_net.aggr_mlp: ['m2g_gnn.interaction_net.aggr_mlp.0', 'm2g_gnn.interaction_net.aggr_mlp.1', 'm2g_gnn.interaction_net.aggr_mlp.2', 'm2g_gnn.interaction_net.aggr_mlp.3']\n",
      "output_map: ['output_map.0', 'output_map.1', 'output_map.2']\n",
      "mesh_embedder: ['mesh_embedder.0', 'mesh_embedder.1', 'mesh_embedder.2', 'mesh_embedder.3']\n",
      "m2m_embedder: ['m2m_embedder.0', 'm2m_embedder.1', 'm2m_embedder.2', 'm2m_embedder.3']\n",
      "processor.module_0.interaction_net: ['processor.module_0.interaction_net.aggr_module']\n",
      "processor.module_0.interaction_net.edge_mlp: ['processor.module_0.interaction_net.edge_mlp.0', 'processor.module_0.interaction_net.edge_mlp.1', 'processor.module_0.interaction_net.edge_mlp.2', 'processor.module_0.interaction_net.edge_mlp.3']\n",
      "processor.module_0.interaction_net.aggr_mlp: ['processor.module_0.interaction_net.aggr_mlp.0', 'processor.module_0.interaction_net.aggr_mlp.1', 'processor.module_0.interaction_net.aggr_mlp.2', 'processor.module_0.interaction_net.aggr_mlp.3']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "def trace_model_connections(model):\n",
    "    connections = defaultdict(list)\n",
    "\n",
    "    def recurse(obj, depth=0, parent=None):\n",
    "        for name, module in obj.named_children():\n",
    "            current_module_name = f\"{parent}.{name}\" if parent else name\n",
    "\n",
    "            if list(module.children()):  # If the module has children, recurse into them\n",
    "                recurse(module, depth + 1, current_module_name)\n",
    "            else:\n",
    "                connections[parent].append(current_module_name)\n",
    "\n",
    "    recurse(model)\n",
    "    return dict(connections)\n",
    "\n",
    "# Assuming `model` is an instance of your model, such as GraphLAM\n",
    "connections_dict = trace_model_connections(model)\n",
    "\n",
    "# Print the connections dictionary\n",
    "for module, inputs in connections_dict.items():\n",
    "    print(f\"{module}: {inputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_embedder: ['grid_embedder.0']\n",
      "grid_embedder.0: ['grid_embedder.1']\n",
      "grid_embedder.1: ['grid_embedder.2']\n",
      "grid_embedder.2: ['grid_embedder.3']\n",
      "g2m_embedder: ['g2m_embedder.0']\n",
      "g2m_embedder.0: ['g2m_embedder.1']\n",
      "g2m_embedder.1: ['g2m_embedder.2']\n",
      "g2m_embedder.2: ['g2m_embedder.3']\n",
      "m2g_embedder: ['m2g_embedder.0']\n",
      "m2g_embedder.0: ['m2g_embedder.1']\n",
      "m2g_embedder.1: ['m2g_embedder.2']\n",
      "m2g_embedder.2: ['m2g_embedder.3']\n",
      "g2m_gnn.interaction_net: ['g2m_gnn.interaction_net.aggr_module']\n",
      "g2m_gnn.interaction_net.edge_mlp: ['g2m_gnn.interaction_net.edge_mlp.0']\n",
      "g2m_gnn.interaction_net.edge_mlp.0: ['g2m_gnn.interaction_net.edge_mlp.1']\n",
      "g2m_gnn.interaction_net.edge_mlp.1: ['g2m_gnn.interaction_net.edge_mlp.2']\n",
      "g2m_gnn.interaction_net.edge_mlp.2: ['g2m_gnn.interaction_net.edge_mlp.3']\n",
      "g2m_gnn.interaction_net.aggr_mlp: ['g2m_gnn.interaction_net.aggr_mlp.0']\n",
      "g2m_gnn.interaction_net.aggr_mlp.0: ['g2m_gnn.interaction_net.aggr_mlp.1']\n",
      "g2m_gnn.interaction_net.aggr_mlp.1: ['g2m_gnn.interaction_net.aggr_mlp.2']\n",
      "g2m_gnn.interaction_net.aggr_mlp.2: ['g2m_gnn.interaction_net.aggr_mlp.3']\n",
      "encoding_grid_mlp: ['encoding_grid_mlp.0']\n",
      "encoding_grid_mlp.0: ['encoding_grid_mlp.1']\n",
      "encoding_grid_mlp.1: ['encoding_grid_mlp.2']\n",
      "encoding_grid_mlp.2: ['encoding_grid_mlp.3']\n",
      "m2g_gnn.interaction_net: ['m2g_gnn.interaction_net.aggr_module']\n",
      "m2g_gnn.interaction_net.edge_mlp: ['m2g_gnn.interaction_net.edge_mlp.0']\n",
      "m2g_gnn.interaction_net.edge_mlp.0: ['m2g_gnn.interaction_net.edge_mlp.1']\n",
      "m2g_gnn.interaction_net.edge_mlp.1: ['m2g_gnn.interaction_net.edge_mlp.2']\n",
      "m2g_gnn.interaction_net.edge_mlp.2: ['m2g_gnn.interaction_net.edge_mlp.3']\n",
      "m2g_gnn.interaction_net.aggr_mlp: ['m2g_gnn.interaction_net.aggr_mlp.0']\n",
      "m2g_gnn.interaction_net.aggr_mlp.0: ['m2g_gnn.interaction_net.aggr_mlp.1']\n",
      "m2g_gnn.interaction_net.aggr_mlp.1: ['m2g_gnn.interaction_net.aggr_mlp.2']\n",
      "m2g_gnn.interaction_net.aggr_mlp.2: ['m2g_gnn.interaction_net.aggr_mlp.3']\n",
      "output_map: ['output_map.0']\n",
      "output_map.0: ['output_map.1']\n",
      "output_map.1: ['output_map.2']\n",
      "mesh_embedder: ['mesh_embedder.0']\n",
      "mesh_embedder.0: ['mesh_embedder.1']\n",
      "mesh_embedder.1: ['mesh_embedder.2']\n",
      "mesh_embedder.2: ['mesh_embedder.3']\n",
      "m2m_embedder: ['m2m_embedder.0']\n",
      "m2m_embedder.0: ['m2m_embedder.1']\n",
      "m2m_embedder.1: ['m2m_embedder.2']\n",
      "m2m_embedder.2: ['m2m_embedder.3']\n",
      "processor.module_0.interaction_net: ['processor.module_0.interaction_net.aggr_module']\n",
      "processor.module_0.interaction_net.edge_mlp: ['processor.module_0.interaction_net.edge_mlp.0']\n",
      "processor.module_0.interaction_net.edge_mlp.0: ['processor.module_0.interaction_net.edge_mlp.1']\n",
      "processor.module_0.interaction_net.edge_mlp.1: ['processor.module_0.interaction_net.edge_mlp.2']\n",
      "processor.module_0.interaction_net.edge_mlp.2: ['processor.module_0.interaction_net.edge_mlp.3']\n",
      "processor.module_0.interaction_net.aggr_mlp: ['processor.module_0.interaction_net.aggr_mlp.0']\n",
      "processor.module_0.interaction_net.aggr_mlp.0: ['processor.module_0.interaction_net.aggr_mlp.1']\n",
      "processor.module_0.interaction_net.aggr_mlp.1: ['processor.module_0.interaction_net.aggr_mlp.2']\n",
      "processor.module_0.interaction_net.aggr_mlp.2: ['processor.module_0.interaction_net.aggr_mlp.3']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def trace_model_connections_via_structure(model):\n",
    "    connections = defaultdict(list)\n",
    "    module_names = list(model.named_modules())\n",
    "    \n",
    "    for i, (name, module) in enumerate(module_names):\n",
    "        if i > 0:  # Skip the first one as it's the entire model\n",
    "            # Get the parent module\n",
    "            parent_name, parent_module = module_names[i-1]\n",
    "            # Only consider leaf modules (modules without children)\n",
    "            if len(list(module.children())) == 0:\n",
    "                connections[parent_name].append(name)\n",
    "                \n",
    "    return dict(connections)\n",
    "\n",
    "# Assuming `model` is your instantiated model, e.g., GraphLAM\n",
    "connections_dict = trace_model_connections_via_structure(model)\n",
    "\n",
    "# Print the connections dictionary\n",
    "for module, connections in connections_dict.items():\n",
    "    print(f\"{module}: {connections}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_num_mesh\n",
      "Loaded graph with 70345 nodes (63784 grid, 6561 mesh)\n",
      "Edges in subgraphs: m2m=51520, g2m=100656, m2g=255136\n",
      "stage1\n",
      "stage2\n",
      "Model Hierarchy:\n",
      "embedding_modules:\n",
      "    GraphLAM: GraphLAM\n",
      "interaction_nets:\n",
      "    GraphLAM.InteractionNetWrapper.InteractionNet: InteractionNet\n",
      "    GraphLAM.Sequential.InteractionNet: InteractionNet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import inspect\n",
    "from collections import defaultdict\n",
    "from neural_lam.interaction_net import InteractionNet\n",
    " \n",
    "def trace_model_hierarchy(model):\n",
    "    \"\"\"\n",
    "    Traces the given model to extract and print the interaction nets, embedding modules,\n",
    "    and their hierarchical/computational relationships.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to trace.\n",
    "    \n",
    "    Returns:\n",
    "        hierarchy (dict): A nested dictionary representing the model's hierarchy.\n",
    "    \"\"\"\n",
    "    hierarchy = defaultdict(dict)\n",
    "    \n",
    "    def trace_module(module, parent_name=\"\"):\n",
    "        \"\"\"\n",
    "        Recursively traces the modules and stores information about\n",
    "        Interaction Nets, Embedding Modules, and the hierarchy.\n",
    "        \"\"\"\n",
    "        # Name of the current module\n",
    "        module_name = parent_name + ('.' if parent_name else '') + type(module).__name__\n",
    "        \n",
    "        # Check if the module is an InteractionNetWrapper or InteractionNet\n",
    "        if isinstance(module, (InteractionNet)):\n",
    "            hierarchy['interaction_nets'][module_name] = module\n",
    "        \n",
    "        # Check if the module is an embedding module (MLP in this case)\n",
    "        if hasattr(module, 'mlp_blueprint_end'):\n",
    "            hierarchy['embedding_modules'][module_name] = module\n",
    "        \n",
    "        # Recursively trace child modules\n",
    "        for name, child in module.named_children():\n",
    "            trace_module(child, parent_name=module_name)\n",
    "    \n",
    "    # Start tracing from the given model\n",
    "    trace_module(model)\n",
    "    \n",
    "    # Function to print the hierarchy in a readable format\n",
    "    def print_hierarchy(hierarchy, indent=0):\n",
    "        \"\"\"\n",
    "        Recursively prints the model hierarchy.\n",
    "        \"\"\"\n",
    "        for key, value in hierarchy.items():\n",
    "            if isinstance(value, dict):\n",
    "                print(\" \" * indent + f\"{key}:\")\n",
    "                print_hierarchy(value, indent + 4)\n",
    "            else:\n",
    "                print(\" \" * indent + f\"{key}: {type(value).__name__}\")\n",
    "\n",
    "    print(\"Model Hierarchy:\")\n",
    "    print_hierarchy(hierarchy)\n",
    "    \n",
    "    return hierarchy\n",
    "\n",
    "hidden_dim = args.hidden_dim\n",
    "hidden_layers = args.hidden_layers\n",
    "mesh_aggr = args.mesh_aggr\n",
    "lr = args.lr\n",
    "dataset = args.dataset\n",
    "output_std = args.output_std\n",
    "loss = args.loss\n",
    "step_length = args.step_length\n",
    "n_example_pred = args.n_example_pred\n",
    "graph = args.graph\n",
    "processor_layers = args.processor_layers\n",
    "model = GraphLAM(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n",
    "\n",
    "# Cre\n",
    "# For BaseHiGraphModel (assuming required arguments are passed)\n",
    "# args = ...  # Populate with required arguments for BaseHiGraphModel\n",
    "# base_hi_graph_model = BaseHiGraphModel(args)\n",
    "\n",
    "# Trace the models\n",
    "graph_lam_hierarchy = trace_model_hierarchy(model)\n",
    "# base_hi_graph_hierarchy = trace_model_hierarchy(base_hi_graph_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_num_mesh\n",
      "Loaded graph with 70345 nodes (63784 grid, 6561 mesh)\n",
      "Edges in subgraphs: m2m=51520, g2m=100656, m2g=255136\n",
      "stage1\n",
      "stage2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BaseGraphModel.predict_step() missing 3 required positional arguments: 'prev_prev_state', 'batch_static_features', and 'forcing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m processor_layers \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mprocessor_layers\n\u001b[1;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m GraphLAM(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n\u001b[0;32m---> 60\u001b[0m model_io \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_lightning_model_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Print the module I/O information\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_name, (input_names, output_names) \u001b[38;5;129;01min\u001b[39;00m model_io\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[72], line 38\u001b[0m, in \u001b[0;36mtrace_lightning_model_io\u001b[0;34m(model, input_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m         model(dummy_input)\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseGraphModel.predict_step() missing 3 required positional arguments: 'prev_prev_state', 'batch_static_features', and 'forcing'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def trace_lightning_model_io(model, input_size):\n",
    "    \"\"\"\n",
    "    Traces the PyTorch Lightning model to get the names of input and output tensors \n",
    "    along with the module hierarchy.\n",
    "\n",
    "    Args:\n",
    "        model (pl.LightningModule): The PyTorch Lightning model to trace.\n",
    "        input_size (tuple): The size of the input tensor (e.g., (1, 3, 224, 224) for an image model).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are module names and values are tuples of (input_tensor_names, output_tensor_names).\n",
    "    \"\"\"\n",
    "    def register_hooks(module, module_name, io_dict):\n",
    "        def hook(module, input, output):\n",
    "            input_names = [f\"{module_name}_input_{i}\" for i in range(len(input))]\n",
    "            output_names = [f\"{module_name}_output_{i}\" for i in range(len(output) if isinstance(output, tuple) else 1)]\n",
    "            io_dict[module_name] = (input_names, output_names)\n",
    "        \n",
    "        module.register_forward_hook(hook)\n",
    "\n",
    "    io_dict = {}\n",
    "\n",
    "    # Register hooks to all modules\n",
    "    for name, module in model.named_modules():\n",
    "        register_hooks(module, name, io_dict)\n",
    "\n",
    "    # Create a dummy input tensor based on the input size\n",
    "    dummy_input = torch.randn(input_size)\n",
    "\n",
    "    # Perform a forward pass using PyTorch Lightning's predict method to trigger the hooks\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if hasattr(model, \"predict_step\"):\n",
    "            model.predict_step(dummy_input)\n",
    "        else:\n",
    "            model(dummy_input)\n",
    "\n",
    "    return io_dict\n",
    "\n",
    "# Example usage:\n",
    "# Assuming model is an instance of your PyTorch Lightning model class\n",
    "# Replace (1, 3, 224, 224) with the appropriate input size for your model\n",
    "hidden_dim = args.hidden_dim\n",
    "hidden_layers = args.hidden_layers\n",
    "mesh_aggr = args.mesh_aggr\n",
    "lr = args.lr\n",
    "dataset = args.dataset\n",
    "output_std = args.output_std\n",
    "loss = args.loss\n",
    "step_length = args.step_length\n",
    "n_example_pred = args.n_example_pred\n",
    "graph = args.graph\n",
    "processor_layers = args.processor_layers\n",
    "model = GraphLAM(hidden_dim, hidden_layers, mesh_aggr,lr, dataset, output_std, loss, step_length, n_example_pred,graph,processor_layers)\n",
    "\n",
    "model_io = trace_lightning_model_io(model, (1, 3, 224, 224))\n",
    "\n",
    "# Print the module I/O information\n",
    "for module_name, (input_names, output_names) in model_io.items():\n",
    "    print(f\"Module: {module_name}\")\n",
    "    print(f\"  Input Tensors: {input_names}\")\n",
    "    print(f\"  Output Tensors: {output_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 48\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m io_dict\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Assuming model is an instance of your PyTorch Lightning model class\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# And dataloader is your DataLoader providing inputs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# model = GraphLAM(...)  # Initialize with appropriate arguments\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# eval_loader = torch.utils.data.DataLoader(...)  # Set up your DataLoader\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m model_io \u001b[38;5;241m=\u001b[39m trace_lightning_model_io_with_loader(model, \u001b[43meval_loader\u001b[49m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Print the module I/O information\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_name, (input_names, output_names) \u001b[38;5;129;01min\u001b[39;00m model_io\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def trace_lightning_model_io_with_loader(model, dataloader):\n",
    "    \"\"\"\n",
    "    Traces the PyTorch Lightning model to get the names of input and output tensors \n",
    "    along with the module hierarchy using a provided DataLoader.\n",
    "\n",
    "    Args:\n",
    "        model (pl.LightningModule): The PyTorch Lightning model to trace.\n",
    "        dataloader (torch.utils.data.DataLoader): The DataLoader to supply inputs to the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are module names and values are tuples of (input_tensor_names, output_tensor_names).\n",
    "    \"\"\"\n",
    "    def register_hooks(module, module_name, io_dict):\n",
    "        def hook(module, input, output):\n",
    "            input_names = [f\"{module_name}_input_{i}\" for i in range(len(input))]\n",
    "            output_names = [f\"{module_name}_output_{i}\" for i in range(len(output) if isinstance(output, tuple) else 1)]\n",
    "            io_dict[module_name] = (input_names, output_names)\n",
    "        \n",
    "        module.register_forward_hook(hook)\n",
    "\n",
    "    io_dict = {}\n",
    "\n",
    "    # Register hooks to all modules\n",
    "    for name, module in model.named_modules():\n",
    "        register_hooks(module, name, io_dict)\n",
    "\n",
    "    # Perform a forward pass using the dataloader to trigger the hooks\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            model.common_step(batch)  # Assuming common_step is used in predict_step or similar\n",
    "            break  # Only need one batch to trace\n",
    "\n",
    "    return io_dict\n",
    "\n",
    "# Example usage:\n",
    "# Assuming model is an instance of your PyTorch Lightning model class\n",
    "# And dataloader is your DataLoader providing inputs\n",
    "\n",
    "# Create an instance of your model and dataloader\n",
    "# model = GraphLAM(...)  # Initialize with appropriate arguments\n",
    "# eval_loader = torch.utils.data.DataLoader(...)  # Set up your DataLoader\n",
    "\n",
    "model_io = trace_lightning_model_io_with_loader(model, eval_loader)\n",
    "\n",
    "# Print the module I/O information\n",
    "for module_name, (input_names, output_names) in model_io.items():\n",
    "    print(f\"Module: {module_name}\")\n",
    "    print(f\"  Input Tensors: {input_names}\")\n",
    "    print(f\"  Output Tensors: {output_names}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
